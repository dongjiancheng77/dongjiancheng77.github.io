---
https://github.com/tianyi-lab/Cherry_LLMlayout: post
title:  "From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning"
date:   2023-12-10 21:21:53 +00:00
image: /images/method_overview.png
categories: Talks
paper: https://arxiv.org/abs/2308.12032
code: https://github.com/tianyi-lab/Cherry_LLM
---
The Instruction-Following Difficulty (IFD) metric, emerges as a pivotal metric to identify discrepancies between a model's expected responses and its intrinsic generation capability. Through the application of IFD, cherry samples can be pinpointed, leading to a marked uptick in model training efficiency. Empirical validations on datasets like Alpaca and WizardLM underpin our findings; with a mere 10% of original data input, our strategy showcases improved results.
